============================================================
WEIGHTED vs UNWEIGHTED INCOMPLETE U-STATISTICS
MNIST Dataset
============================================================

Device: cuda

------------------------------------------------------------
LOADING MNIST DATASET
------------------------------------------------------------

Class distribution:
  Dominant class 0: 2250 (45.0%)
  Rarest 5 classes: [295 267 242 218 202]
  Total samples: 5000

============================================================
EXPERIMENT 1: WEIGHTED U-STATISTICS
============================================================

============================================================
Training with WEIGHTED incomplete U-statistics
M=3000 tuples per epoch
Batch size=64
Rarest classes: [9, 8, 7, 6, 5] with counts [202 218 242 267 295]
============================================================
{(0, True): 0.7614598798363428, (0, False): 1.7142224162598574, (1, True): 1.0834942430111947, (1, False): 1.0834942430111947, (2, True): 1.1331099511467826, (2, False): 1.1331099511467826, (3, True): 1.1807025110953313, (3, False): 1.1807025110953313, (4, True): 1.2259398983605572, (4, False): 1.2259398983605572, (5, True): 1.2671554737626272, (5, False): 1.2671554737626272, (6, True): 1.305328293530686, (6, False): 1.305328293530686, (7, True): 1.3401834241660553, (7, False): 1.3401834241660553, (8, True): 1.3743409799154283, (8, False): 1.3743409799154283, (9, True): 1.3974970060124623, (9, False): 1.3974970060124623}
 - Update model at epoch 0, new best = 1.02785
 - Update model at epoch 1, new best = 0.85866
 - Update model at epoch 2, new best = 0.82624
 - Update model at epoch 3, new best = 0.78872
 - Update model at epoch 4, new best = 0.76184
 - Update model at epoch 5, new best = 0.75918
 - Update model at epoch 6, new best = 0.74816
 - Update model at epoch 7, new best = 0.71967
 - Update model at epoch 9, new best = 0.71379
 - Update model at epoch 12, new best = 0.71213
 - Update model at epoch 14, new best = 0.71050
 - Update model at epoch 16, new best = 0.69669
Epoch  20 | Train Loss: 0.7035 | Test Loss (rare): 0.9473 | Time: 0.72s
 - Update model at epoch 20, new best = 0.68974
 - Update model at epoch 26, new best = 0.67851
 - Update model at epoch 28, new best = 0.67237
 - Update model at epoch 29, new best = 0.65096
 - Update model at epoch 30, new best = 0.63389
 - Update model at epoch 32, new best = 0.62089
 - Update model at epoch 34, new best = 0.60219
 - Update model at epoch 35, new best = 0.57816
Epoch  40 | Train Loss: 0.5799 | Test Loss (rare): 0.9118 | Time: 0.71s
 - Update model at epoch 40, new best = 0.56258
 - Update model at epoch 45, new best = 0.55657
 - Update model at epoch 53, new best = 0.55433
 - Update model at epoch 55, new best = 0.54446
Epoch  60 | Train Loss: 0.5446 | Test Loss (rare): 0.8631 | Time: 0.71s
 - Update model at epoch 61, new best = 0.53989
 - Update model at epoch 63, new best = 0.53444
 - Update model at epoch 72, new best = 0.53159
 - Update model at epoch 73, new best = 0.52772
 - Update model at epoch 75, new best = 0.52502
Epoch  80 | Train Loss: 0.5265 | Test Loss (rare): 0.8824 | Time: 0.71s
 - Update model at epoch 87, new best = 0.51996
Epoch 100 | Train Loss: 0.5382 | Test Loss (rare): 0.8771 | Time: 0.71s
 - Update model at epoch 111, new best = 0.51852
 - Update model at epoch 112, new best = 0.51764
 - Update model at epoch 117, new best = 0.51678
Epoch 120 | Train Loss: 0.5253 | Test Loss (rare): 0.8411 | Time: 0.71s
 - Update model at epoch 126, new best = 0.51619
 - Update model at epoch 137, new best = 0.51510
Epoch 140 | Train Loss: 0.5293 | Test Loss (rare): 0.9377 | Time: 0.71s
 - Update model at epoch 141, new best = 0.50960
Epoch 160 | Train Loss: 0.5251 | Test Loss (rare): 0.8413 | Time: 0.71s
Epoch 180 | Train Loss: 0.5131 | Test Loss (rare): 0.8986 | Time: 0.71s
 - Update model at epoch 182, new best = 0.50582
Epoch 200 | Train Loss: 0.5138 | Test Loss (rare): 0.8782 | Time: 0.71s
Epoch 220 | Train Loss: 0.5189 | Test Loss (rare): 0.8695 | Time: 0.71s
Epoch 240 | Train Loss: 0.5155 | Test Loss (rare): 0.8884 | Time: 0.72s
 - Update model at epoch 247, new best = 0.50434
Epoch 260 | Train Loss: 0.5136 | Test Loss (rare): 0.9052 | Time: 0.70s
 - Update model at epoch 271, new best = 0.50258
 - Update model at epoch 273, new best = 0.50058
Epoch 280 | Train Loss: 0.5055 | Test Loss (rare): 0.8601 | Time: 0.71s
Epoch 300 | Train Loss: 0.5095 | Test Loss (rare): 0.8236 | Time: 0.70s

Weighted training completed in 217.93s

--- Training classifier on WEIGHTED encoder ---

============================================================
TRAINING LINEAR CLASSIFIER
============================================================
Training for 100 epochs...
Train representations: torch.Size([5000, 64])
Test representations: torch.Size([4000, 64])
Epoch   1 | Loss: 2.0196 | Train Acc: 96.60%
Epoch  20 | Loss: 0.0659 | Train Acc: 99.88%
Epoch  40 | Loss: 0.0193 | Train Acc: 99.92%
Epoch  60 | Loss: 0.0099 | Train Acc: 99.92%
Epoch  80 | Loss: 0.0064 | Train Acc: 99.92%
Epoch 100 | Loss: 0.0046 | Train Acc: 99.92%

============================================================
CLASSIFICATION RESULTS - WEIGHTED ENCODER
============================================================

============================================================
EVALUATING CLASSIFIER ON RARE CLASSES
============================================================

Overall Test Accuracy: 94.08%

------------------------------------------------------------
RARE CLASS METRICS
------------------------------------------------------------
Class    Support    Precision    Recall       F1-Score    
------------------------------------------------------------
9        400        0.9137       0.9000       0.9068      
8        400        0.9426       0.9025       0.9221      
7        400        0.9735       0.9200       0.9460      
6        400        0.9695       0.9525       0.9609      
5        400        0.9236       0.9375       0.9305      
------------------------------------------------------------

Average across rare classes:
  Precision: 0.9446
  Recall:    0.9225
  F1-Score:  0.9333
============================================================

============================================================
EXPERIMENT 2: UNWEIGHTED U-STATISTICS
============================================================

============================================================
Training with UNWEIGHTED incomplete U-statistics
M=3000 tuples per epoch
Batch size=64
Rarest classes: [9, 8, 7, 6, 5] with counts [202 218 242 267 295]
============================================================
{(0, True): 0.7614598798363428, (0, False): 1.7142224162598574, (1, True): 1.0834942430111947, (1, False): 1.0834942430111947, (2, True): 1.1331099511467826, (2, False): 1.1331099511467826, (3, True): 1.1807025110953313, (3, False): 1.1807025110953313, (4, True): 1.2259398983605572, (4, False): 1.2259398983605572, (5, True): 1.2671554737626272, (5, False): 1.2671554737626272, (6, True): 1.305328293530686, (6, False): 1.305328293530686, (7, True): 1.3401834241660553, (7, False): 1.3401834241660553, (8, True): 1.3743409799154283, (8, False): 1.3743409799154283, (9, True): 1.3974970060124623, (9, False): 1.3974970060124623}
 - Update model at epoch 0, new best = 0.70117
 - Update model at epoch 1, new best = 0.53790
 - Update model at epoch 2, new best = 0.48175
 - Update model at epoch 3, new best = 0.45843
 - Update model at epoch 5, new best = 0.45539
 - Update model at epoch 6, new best = 0.44336
 - Update model at epoch 7, new best = 0.41996
 - Update model at epoch 8, new best = 0.41577
 - Update model at epoch 9, new best = 0.40080
 - Update model at epoch 11, new best = 0.39403
 - Update model at epoch 12, new best = 0.39310
 - Update model at epoch 13, new best = 0.39276
 - Update model at epoch 19, new best = 0.38832
Epoch  20 | Train Loss: 0.3883 | Test Loss (rare): 1.0210 | Time: 0.40s
 - Update model at epoch 20, new best = 0.38643
 - Update model at epoch 21, new best = 0.38617
 - Update model at epoch 22, new best = 0.38175
 - Update model at epoch 25, new best = 0.37829
 - Update model at epoch 27, new best = 0.37476
 - Update model at epoch 28, new best = 0.37130
 - Update model at epoch 30, new best = 0.36676
Epoch  40 | Train Loss: 0.3687 | Test Loss (rare): 0.9541 | Time: 0.40s
 - Update model at epoch 43, new best = 0.36519
 - Update model at epoch 44, new best = 0.36190
 - Update model at epoch 48, new best = 0.36080
 - Update model at epoch 50, new best = 0.35913
 - Update model at epoch 51, new best = 0.35720
 - Update model at epoch 54, new best = 0.35713
 - Update model at epoch 56, new best = 0.35116
Epoch  60 | Train Loss: 0.3576 | Test Loss (rare): 0.9551 | Time: 0.40s
 - Update model at epoch 63, new best = 0.34531
Epoch  80 | Train Loss: 0.3558 | Test Loss (rare): 0.9771 | Time: 0.40s
 - Update model at epoch 82, new best = 0.34481
 - Update model at epoch 95, new best = 0.34056
Epoch 100 | Train Loss: 0.3536 | Test Loss (rare): 1.0445 | Time: 0.40s
Epoch 120 | Train Loss: 0.3420 | Test Loss (rare): 1.0415 | Time: 0.40s
 - Update model at epoch 122, new best = 0.34051
Epoch 140 | Train Loss: 0.3476 | Test Loss (rare): 0.9616 | Time: 0.41s
 - Update model at epoch 140, new best = 0.33899
 - Update model at epoch 143, new best = 0.33424
Epoch 160 | Train Loss: 0.3412 | Test Loss (rare): 1.1100 | Time: 0.40s
 - Update model at epoch 160, new best = 0.33162
 - Update model at epoch 172, new best = 0.32719
Epoch 180 | Train Loss: 0.3502 | Test Loss (rare): 1.0412 | Time: 0.40s
 - Update model at epoch 196, new best = 0.31814
Epoch 200 | Train Loss: 0.3450 | Test Loss (rare): 1.0039 | Time: 0.40s
Epoch 220 | Train Loss: 0.3618 | Test Loss (rare): 0.9170 | Time: 0.40s
Epoch 240 | Train Loss: 0.3327 | Test Loss (rare): 1.0270 | Time: 0.40s
Epoch 260 | Train Loss: 0.3202 | Test Loss (rare): 1.3107 | Time: 0.40s
Epoch 280 | Train Loss: 0.3327 | Test Loss (rare): 1.0855 | Time: 0.40s
 - Update model at epoch 294, new best = 0.30685
 - Update model at epoch 296, new best = 0.29980
Epoch 300 | Train Loss: 0.3599 | Test Loss (rare): 1.0481 | Time: 0.40s

Unweighted training completed in 123.60s

--- Training classifier on UNWEIGHTED encoder ---

============================================================
TRAINING LINEAR CLASSIFIER
============================================================
Training for 100 epochs...
Train representations: torch.Size([5000, 64])
Test representations: torch.Size([4000, 64])
Epoch   1 | Loss: 2.0464 | Train Acc: 93.58%
Epoch  20 | Loss: 0.1021 | Train Acc: 99.92%
Epoch  40 | Loss: 0.0253 | Train Acc: 99.94%
Epoch  60 | Loss: 0.0099 | Train Acc: 99.96%
Epoch  80 | Loss: 0.0045 | Train Acc: 99.98%
Epoch 100 | Loss: 0.0022 | Train Acc: 100.00%

============================================================
CLASSIFICATION RESULTS - UNWEIGHTED ENCODER
============================================================

============================================================
EVALUATING CLASSIFIER ON RARE CLASSES
============================================================

Overall Test Accuracy: 92.67%

------------------------------------------------------------
RARE CLASS METRICS
------------------------------------------------------------
Class    Support    Precision    Recall       F1-Score    
------------------------------------------------------------
9        400        0.8878       0.8700       0.8788      
8        400        0.9231       0.9000       0.9114      
7        400        0.9395       0.9325       0.9360      
6        400        0.9763       0.9250       0.9499      
5        400        0.9082       0.9400       0.9238      
------------------------------------------------------------

Average across rare classes:
  Precision: 0.9270
  Recall:    0.9135
  F1-Score:  0.9200
============================================================

============================================================
GENERATING COMPARISON PLOTS
============================================================

============================================================
ALL EXPERIMENTS COMPLETED!
============================================================
